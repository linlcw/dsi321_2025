{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data from lakeFS to a local parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config.path_config import lakefs_s3_path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"tweets-repo\"\n",
    "branch_name = \"main\"\n",
    "path = \"tweets.parquet\"\n",
    "lakefs_s3_path = f\"s3://{repo_name}/{branch_name}/{path}\"\n",
    "def data_from_lakefs(lakefs_endpoint: str = \"http://localhost:8001/\", columns: list[str] = None):\n",
    "    storage_options = {\n",
    "        \"key\": os.getenv(\"ACCESS_KEY\"),\n",
    "        \"secret\": os.getenv(\"SECRET_KEY\"),\n",
    "        \"client_kwargs\": {\n",
    "            \"endpoint_url\": lakefs_endpoint\n",
    "        }\n",
    "    }\n",
    "    df = pd.read_parquet(\n",
    "        lakefs_s3_path,\n",
    "        columns=columns,\n",
    "        storage_options=storage_options,\n",
    "        engine='pyarrow',\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df = data_from_lakefs()\n",
    "df = df.rename(columns={'postTimeRaw': 'timestamp'})\n",
    "df['year'] = df['year'].astype('int32')\n",
    "df['month'] = df['month'].astype('int32')\n",
    "df['day'] = df['day'].astype('int32')\n",
    "df['timestamp'] = df['timestamp'].dt.tz_localize('UTC')\n",
    "df.to_parquet('../data/data.parquet', engine='pyarrow')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verlify the data types of a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verlify = pd.read_parquet('../data/data.parquet', engine='pyarrow')\n",
    "df_verlify.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype ของ dataframe เก่า vs จาก read มาใหม่\n",
    "df.dtypes == df_verlify.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check records > 1000\n",
    "len(df_verlify) > 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data duplicated \n",
    "df_verlify.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null\n",
    "df_verlify.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
